---
title: "ETC513 Assignment 3: Comparison of Energy and Pollution by Country"
author:
- familyname: Chen
  othernames: Shaohu
  address: Monash Universtidy
  email: sche0232@student.monash.edu
  correspondingauthor: true
  qualifications:  Master of Business Analytics(In Progress)
- familyname: Duan
  othernames: Qian
  address: Monash Universtidy
  email: qdua0005@student.monash.edu
  correspondingauthor: true
  qualifications:  Master of Business Analytics(In Progress)
- familyname: Tsou
  othernames: Tina
  address: Monash Universtidy
  email: ttso0004@student.monash.edu
  correspondingauthor: true
  qualifications:  Master of Business Analytics(In Progress)
department: Our consultancy \newline add names &\newline add names
organization: Australian Government COVID19
bibliography: references.bib
biblio-style: authoryear-comp
linestretch: 1.5
output:
  bookdown::pdf_document2:
    template: monashreport2.tex
    fig_caption: yes
    fig_height: 5
    fig_width: 8
    includes:
      in_header: preamble.tex
    keep_tex: yes
    number_sections: yes
    citation_package: biblatex
    toc: false
editor_options: 
  chunk_output_type: console
---
```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE, 
                      warning = FALSE,
                      fig.align = 'center',
                      cache = TRUE)
```

```{r load libraries}
# Libraries
library(tidyverse)
library(readr)
library(kableExtra)
library(bookdown)
library(ggplot2)
library(fastDummies)
library(scales)
library(broom)
library(stargazer)
library(pROC)
```


```{r data}
drive <- read_csv(here::here("Data/practicaldrivingexaminationresults.csv"))
```

\section*{Introduction}




\section*{Step 1}




\section*{Step 2}


\section*{Step 3}

In the following section, we will be analyzing the relationship between *Booking Type* and *Exam Result*. 

```{r frequency, fig.cap= "Frequency Plot between Booking Type and Exam Result", fig.width= 5, fig.height= 4}
table <- table(drive$`Booking Type`,drive$`Exam Result`)
tab.prop <-  prop.table(table, 1)
tab.df <- as.data.frame(tab.prop) #make frequency table into data frame
names(tab.df) <- c("Booking Type", "Result", "frequency")

ggplot(tab.df, 
       aes(x=`Booking Type`, y = frequency, fill=Result)) + 
        geom_col() +theme_minimal()
```

The frequency plot, Figure \@ref(fig:frequency), between *Booking Type* and *Exam Result* shows that the percentages of people who passed the exam are similar for both driving school and private.

Since the response variable and predictor variable are categorical variables, they will have to be converted into dummy variables(0 & 1). Then, following @logisticregregression, I ran a logistic regression to analyze their relationship. The following is the formula for the regression *logmodel*:

$Y$~$B(p)$, $log(\frac{p}{1-p}) = \beta_0 +\beta_1 X + \epsilon$
  
+ $\beta_0$ is the intercept.

+ $\beta_1$ is the coefficient of *Booking Type_Private*

+ X is *Booking Type_Private* taking values 0 or 1

```{r regression}
drivedum <- dummy_cols(drive, select_columns =  c('Booking Type', 'Exam Result'),
                       remove_selected_columns = TRUE)

logmodel <- glm(`Exam Result_PASS` ~`Booking Type_Private`, 
                family=binomial(link='logit'), data=drivedum)
```

```{r results1, tab.caption = "Regression with *Booking Type_Private*", results = "asis", message = FALSE}
stargazer(logmodel,
          title= "Regression with *Booking Type_Private*",
          align = TRUE,
          type = "latex",
          style = "default",
          header = FALSE,
          no.space=TRUE)
```

Table \@ref(tab:results1) shows the regression summary. *Booking Type_Private* has p-value close to 0 which means it is statistically significant. Due to the variable being a dummy variable relative to booking type driving school, the coefficient indicates that *Booking Type_Private* affects the passing of an exam negatively compared to *Booking Type_Driving School*. Private booking reduces the log odds by 0.061.

```{r anova, tab.caption = "ANOVA for logmodel1"}
anova(logmodel, test="Chisq") %>% 
  kable(booktabs =TRUE,
        caption = "Anova for logmodel") %>% 
  kable_styling(position = "center")
```

ANOVA test, table \@ref(tab:anova), on the *logmodel* analyzes the table of deviance which shows how well the x variable is doing in comparison to the null model. Here we can see that the drop in deviance is quite small despite having low p-value. 

Next, we test the fit of the model by looking at the receiver operating characteristic (ROC) curve.
```{r roc, fig.cap="ROC Cuve of logmodel1", fig.width=5, fig.height= 4}
predpr <- predict(logmodel,type=c("response"))
roccurve <- roc(drivedum$`Exam Result_PASS` ~ predpr)

plot(roccurve)
```
Figure \@ref(fig:roc) shows the ROC curve of the *logmodel*. It is basically a 45 degree diagonal line which indicates the model has no discrimination ability. 

Area under the curve "...gives the probability that the model correctly ranks such pairs of observations" @bartlett_2014. The area under the curve for this model is `r pROC::auc(roccurve)`. In conclusion, the predictor just makes random guesses.

We try to improve the model by adding more variables to the function: 

$Y$~$B(p)$, $log(\frac{p}{1-p}) = \beta_0 +\beta_1 X_1 +\beta_2 X_2 + \epsilon$

$X_2$ is *Number of Examinations* taken by each examinee.

```{r, regreesion2}
logmodel2 <- glm(`Exam Result_PASS` ~`Booking Type_Private` + `Number of Examinations`,
                family=binomial(link='logit'),data=drivedum)
```

```{r comparison, tab.caption= "Regression Results",results = "asis"}
stargazer(logmodel, logmodel2,
          title="Regression Results",
          align=TRUE,
          type = "latex",
          style = "default",
          header = FALSE,
          no.space=TRUE)
```

Table \@ref(tab:comparison) shows the two regression summary side-by-side. The regression with *Number of Examinations* has AIC of 333404. It is slightly lower than the AIC of the previous regression which was 333483. Thus, in comparison, having this one extra variable improved the function significantly (statistically). However, a simple calculation of area under ROC curve for logmodel2 indicates that the model is even worse than the first. 
```{r roc2, fig.cap="ROC Cuve of logmodel1"}
predpr2 <- predict(logmodel2,type=c("response"))
roccurve2 <- roc(drivedum$`Exam Result_PASS` ~ predpr2)

auc(roccurve2)
```

\section*{Conclusion}
In conclusion, we've shown that higher pass rate in certain districts is not always an absolute reflection on whether the district has better driving program. Rather, it is an outcome of locations with lower examinees in general. For locations with more examinees, there would be more variations in their outcome thus more fails. 

Next, we shown that automatic cars have the lowest pass rate overall, and that motorcycle (over 250cc) has the highest pass rate. Older people (66 and above) also tend to fail their vehicle tests more. But ultimately pass rate for each vehicle type and majority of the age group is over 50%.

Last but not least, although, there is statistical relationship between the booking type and the exam outcome, the affect is pretty small. Furthermore, the current variables are inadequate in creating a good model to predict the outcome. 

This is also a shortcoming with the data we currently have. Because it contains very limited variables, it is hard to create a better fit model that can predict the outcome accurately.

